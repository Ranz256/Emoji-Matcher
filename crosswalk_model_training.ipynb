{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJMgJ+oXodnQCQ2MRqPwAS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranz256/Emoji-Matcher/blob/main/crosswalk_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "gaqoC_clLhsT",
        "outputId": "a853e321-03ff-4ec6-8d23-a7f203307c7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-af8f8f81-23ea-4e72-8e4d-c30d1506ec24\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-af8f8f81-23ea-4e72-8e4d-c30d1506ec24\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving crosswalk-detection.v1i.yolov8.zip to crosswalk-detection.v1i.yolov8.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZWDiFyIJ66d",
        "outputId": "b11ceb6d-95d9-4b0e-9f89-85de03e42fea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.131)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Ultralytics 8.3.131 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/crosswalk-detection/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_crosswalk2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=crosswalk_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=crosswalk_yolo/yolov8n_crosswalk2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1387.2±550.6 MB/s, size: 113.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/crosswalk-detection/train/labels.cache... 734 images, 0 backgrounds, 0 corrupt: 100%|██████████| 734/734 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1555.7±477.0 MB/s, size: 135.3 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/crosswalk-detection/valid/labels.cache... 210 images, 0 backgrounds, 0 corrupt: 100%|██████████| 210/210 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to crosswalk_yolo/yolov8n_crosswalk2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mcrosswalk_yolo/yolov8n_crosswalk2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50         0G      1.328      2.149      1.715         36        640: 100%|██████████| 46/46 [10:19<00:00, 13.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  8.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.492      0.281      0.303      0.107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50         0G      1.269      1.726      1.647         35        640: 100%|██████████| 46/46 [09:57<00:00, 13.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272     0.0815      0.287     0.0514     0.0147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50         0G      1.303       1.57      1.647         49        640: 100%|██████████| 46/46 [09:57<00:00, 12.99s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272     0.0918      0.125     0.0544     0.0205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50         0G      1.263      1.449       1.61         46        640: 100%|██████████| 46/46 [10:02<00:00, 13.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.339      0.489      0.328      0.142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50         0G      1.289      1.377      1.636         50        640: 100%|██████████| 46/46 [09:57<00:00, 13.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.447      0.467      0.299      0.116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50         0G      1.228      1.262      1.571         38        640: 100%|██████████| 46/46 [10:00<00:00, 13.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.696      0.581      0.614      0.331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50         0G      1.176      1.186      1.541         45        640: 100%|██████████| 46/46 [09:56<00:00, 12.97s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:04<00:00,  9.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.825      0.608      0.722        0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50         0G      1.185      1.156      1.528         41        640: 100%|██████████| 46/46 [10:02<00:00, 13.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.832      0.662      0.746      0.459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50         0G      1.142      1.084      1.501         39        640: 100%|██████████| 46/46 [10:00<00:00, 13.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.804      0.676      0.764      0.443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50         0G      1.114      1.086      1.488         37        640: 100%|██████████| 46/46 [10:02<00:00, 13.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.782      0.621       0.67      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50         0G      1.045     0.9988      1.447         43        640: 100%|██████████| 46/46 [10:03<00:00, 13.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  8.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.662      0.607      0.585      0.322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50         0G      1.022     0.9646      1.416         45        640: 100%|██████████| 46/46 [10:02<00:00, 13.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:04<00:00,  9.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.833      0.724      0.775      0.512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50         0G      1.038     0.9137       1.42         47        640: 100%|██████████| 46/46 [10:02<00:00, 13.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  8.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.886      0.741      0.847      0.559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50         0G      1.021      0.914      1.407         43        640: 100%|██████████| 46/46 [10:04<00:00, 13.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:03<00:00,  9.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.906      0.761      0.846      0.522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50         0G     0.9843     0.8784       1.38         35        640: 100%|██████████| 46/46 [10:01<00:00, 13.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.917      0.731      0.876      0.609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50         0G     0.9484     0.8572      1.361         46        640: 100%|██████████| 46/46 [10:03<00:00, 13.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.869      0.778      0.869      0.592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50         0G     0.9507      0.815      1.357         33        640: 100%|██████████| 46/46 [10:29<00:00, 13.68s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  9.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.922       0.74      0.852       0.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50         0G     0.9032     0.8024      1.326         35        640: 100%|██████████| 46/46 [10:01<00:00, 13.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:03<00:00,  9.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.905      0.766      0.855      0.569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50         0G     0.8838     0.7666      1.313         40        640: 100%|██████████| 46/46 [10:02<00:00, 13.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.889       0.82       0.91      0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50         0G     0.8905     0.7702      1.311         39        640: 100%|██████████| 46/46 [10:01<00:00, 13.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  8.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.898      0.801      0.886      0.596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50         0G     0.8721     0.7519       1.31         33        640: 100%|██████████| 46/46 [10:01<00:00, 13.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:03<00:00,  9.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.933      0.773      0.885      0.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50         0G     0.8649     0.7385      1.292         33        640: 100%|██████████| 46/46 [09:58<00:00, 13.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.956      0.869      0.941      0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50         0G     0.8296     0.7108      1.276         40        640: 100%|██████████| 46/46 [09:56<00:00, 12.96s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.942      0.779      0.908      0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50         0G     0.8201      0.693      1.274         40        640: 100%|██████████| 46/46 [09:55<00:00, 12.95s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:03<00:00,  9.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272       0.92      0.868      0.939      0.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50         0G     0.7862      0.671      1.249         44        640: 100%|██████████| 46/46 [09:56<00:00, 12.96s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.935      0.849      0.922      0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50         0G     0.7903     0.6788      1.248         41        640: 100%|██████████| 46/46 [10:00<00:00, 13.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:59<00:00,  8.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.955      0.862      0.948      0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50         0G     0.7726      0.648      1.232         31        640: 100%|██████████| 46/46 [09:55<00:00, 12.95s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  8.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.919      0.842      0.909      0.661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50         0G     0.7563     0.6396      1.224         43        640: 100%|██████████| 46/46 [09:58<00:00, 13.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272       0.93       0.88      0.949      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50         0G     0.7637     0.6279      1.223         36        640: 100%|██████████| 46/46 [09:57<00:00, 12.99s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  8.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.946      0.904      0.965      0.721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50         0G     0.7311     0.6073      1.204         45        640: 100%|██████████| 46/46 [09:52<00:00, 12.88s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.961      0.912      0.961      0.756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50         0G     0.7134     0.5908      1.187         35        640: 100%|██████████| 46/46 [10:02<00:00, 13.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272       0.96      0.904      0.961      0.776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50         0G     0.7188     0.5975        1.2         41        640: 100%|██████████| 46/46 [10:00<00:00, 13.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  8.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272       0.96      0.892      0.958      0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50         0G     0.6919     0.5714      1.168         36        640: 100%|██████████| 46/46 [10:07<00:00, 13.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.959      0.904      0.964      0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50         0G      0.689     0.5712      1.176         36        640: 100%|██████████| 46/46 [10:00<00:00, 13.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.969      0.912      0.979       0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50         0G     0.6624     0.5712      1.164         41        640: 100%|██████████| 46/46 [10:00<00:00, 13.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.954      0.922      0.974      0.794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50         0G     0.6525     0.5485      1.149         53        640: 100%|██████████| 46/46 [10:01<00:00, 13.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.954      0.921       0.97       0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50         0G     0.6683     0.5505      1.157         27        640: 100%|██████████| 46/46 [09:56<00:00, 12.96s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.983      0.919      0.976      0.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50         0G     0.6386     0.5332      1.151         36        640: 100%|██████████| 46/46 [10:00<00:00, 13.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  8.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.981      0.926      0.978      0.792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50         0G     0.6429     0.5332      1.145         42        640: 100%|██████████| 46/46 [09:55<00:00, 12.95s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.982      0.926      0.983      0.813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50         0G     0.5975     0.4893       1.12         46        640: 100%|██████████| 46/46 [10:08<00:00, 13.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272       0.97      0.941      0.981      0.818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50         0G      0.592      0.529      1.183         14        640: 100%|██████████| 46/46 [09:54<00:00, 12.93s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.976      0.897      0.978      0.813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50         0G     0.5333      0.423      1.126         17        640: 100%|██████████| 46/46 [10:01<00:00, 13.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.988      0.901      0.982      0.819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50         0G     0.5208     0.3992      1.114         15        640: 100%|██████████| 46/46 [10:02<00:00, 13.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.974      0.912       0.98      0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50         0G     0.5088       0.38      1.101         18        640: 100%|██████████| 46/46 [09:51<00:00, 12.86s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:02<00:00,  8.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.976       0.96      0.989      0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50         0G      0.494     0.3753      1.102         18        640: 100%|██████████| 46/46 [10:00<00:00, 13.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272       0.98      0.952       0.99      0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50         0G     0.4672     0.3629      1.075         17        640: 100%|██████████| 46/46 [09:51<00:00, 12.86s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:01<00:00,  8.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.985      0.952      0.991      0.859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50         0G     0.4712     0.3504      1.072         16        640: 100%|██████████| 46/46 [10:01<00:00, 13.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.983      0.967      0.991      0.862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50         0G     0.4376     0.3361      1.046         16        640: 100%|██████████| 46/46 [09:53<00:00, 12.91s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.983      0.952      0.991       0.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50         0G     0.4217      0.331      1.047         14        640: 100%|██████████| 46/46 [10:02<00:00, 13.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:04<00:00,  9.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.985      0.956      0.992      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50         0G     0.4229      0.325      1.055         24        640: 100%|██████████| 46/46 [09:53<00:00, 12.90s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.984      0.967      0.992      0.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 9.204 hours.\n",
            "Optimizer stripped from crosswalk_yolo/yolov8n_crosswalk2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from crosswalk_yolo/yolov8n_crosswalk2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating crosswalk_yolo/yolov8n_crosswalk2/weights/best.pt...\n",
            "Ultralytics 8.3.131 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:58<00:00,  8.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        210        272      0.984      0.967      0.992      0.874\n",
            "Speed: 2.6ms preprocess, 264.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
            "Results saved to \u001b[1mcrosswalk_yolo/yolov8n_crosswalk2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7a6391a5bbd0>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,     0.99608,     0.99608,     0.99608,     0.99608,     0.99608,     0.99608,     0.99608,     0.99608,     0.99608,     0.99608,     0.99608,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,\n",
              "            0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.98855,     0.98855,     0.98855,     0.98855,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,     0.98502,\n",
              "            0.97417,     0.97417,     0.97417,     0.97417,     0.94326,     0.94326,     0.94326,     0.94326,     0.94326,     0.94326,     0.94326,     0.93357,     0.93357,     0.93357,     0.93357,     0.92414,     0.92414,     0.92414,     0.92414,     0.88487,     0.88487,     0.88487,     0.87097,\n",
              "            0.87097,     0.87097,     0.87097,     0.61174,     0.61174,     0.61174,     0.61174,     0.13614,    0.090757,    0.045379,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.28556,     0.28599,     0.45363,     0.52925,     0.58011,     0.61873,     0.64264,     0.66492,     0.68998,     0.70461,     0.72403,      0.7414,     0.75457,     0.76045,     0.76714,     0.78093,     0.78507,     0.79214,     0.80258,     0.80467,     0.80552,     0.80671,     0.81052,\n",
              "            0.81305,     0.81802,     0.82368,     0.82595,     0.82866,     0.83517,     0.84384,     0.84733,     0.84931,     0.85244,     0.85571,     0.85784,     0.85984,      0.8612,     0.86441,     0.86526,     0.87106,     0.87206,     0.87578,     0.87756,     0.88095,     0.88247,       0.883,\n",
              "            0.88354,     0.88407,     0.88459,     0.88511,     0.88606,     0.88851,     0.89122,     0.89262,     0.89343,     0.89708,     0.89763,     0.89818,     0.89859,      0.8988,     0.89901,     0.89922,     0.89943,     0.89964,     0.89985,     0.90071,     0.90344,     0.90671,     0.90845,\n",
              "            0.90964,     0.91044,     0.91172,     0.91351,     0.91602,     0.91689,     0.91765,     0.91864,     0.92154,      0.9219,     0.92227,     0.92263,       0.923,     0.92356,     0.92418,     0.92491,     0.92606,     0.92776,     0.92677,     0.92612,     0.92655,     0.92698,     0.92741,\n",
              "            0.92783,     0.92825,     0.92866,     0.92907,     0.92967,     0.93034,     0.93154,     0.93325,     0.93522,      0.9363,     0.93714,     0.93758,     0.93801,     0.93845,     0.94059,     0.94129,     0.94199,     0.94343,     0.94389,     0.94415,     0.94442,     0.94469,     0.94496,\n",
              "            0.94522,     0.94562,     0.94611,     0.94659,     0.94869,     0.95032,      0.9504,     0.95045,     0.95049,     0.95054,     0.95059,     0.95064,     0.95068,     0.95073,     0.95078,     0.95082,     0.95087,     0.95092,     0.95097,     0.95101,     0.95106,     0.95111,     0.95115,\n",
              "             0.9512,     0.95125,     0.95129,     0.95134,     0.95139,     0.95144,     0.95148,     0.95153,     0.95158,     0.95162,     0.95167,     0.95172,     0.95176,     0.95181,     0.95186,     0.95191,     0.95195,       0.952,     0.95208,     0.95256,     0.95303,     0.95351,     0.95365,\n",
              "             0.9535,     0.95334,     0.95318,     0.95302,     0.95286,     0.95271,     0.95255,     0.95239,     0.95223,     0.95207,     0.95191,     0.95291,     0.95404,     0.95492,     0.95693,     0.95683,     0.95673,     0.95663,     0.95653,     0.95643,     0.95632,     0.95622,     0.95612,\n",
              "            0.95602,     0.95592,     0.95582,     0.95571,     0.95561,     0.95551,     0.95541,     0.95531,     0.95521,     0.95513,     0.95528,     0.95542,     0.95556,     0.95571,     0.95585,     0.95599,     0.95614,     0.95628,     0.95642,     0.95657,     0.95671,     0.95685,     0.95692,\n",
              "              0.957,     0.95708,     0.95715,     0.95723,     0.95731,     0.95739,     0.95746,     0.95754,     0.95762,      0.9577,     0.95777,     0.95785,     0.95793,       0.958,     0.95808,     0.95816,     0.95824,     0.95831,     0.95839,     0.95847,     0.95854,     0.95874,     0.95895,\n",
              "            0.95917,     0.95939,      0.9596,     0.95982,     0.96004,     0.96025,      0.9602,      0.9601,        0.96,      0.9599,      0.9598,     0.95969,     0.95959,     0.95949,     0.95939,     0.95929,     0.95918,     0.95908,     0.95898,     0.95888,     0.95878,     0.95867,     0.95857,\n",
              "            0.95847,     0.95837,     0.95826,     0.95816,     0.95806,     0.95796,     0.95785,     0.95775,     0.95765,     0.95754,     0.95744,     0.95734,     0.95724,     0.95713,     0.95703,     0.95693,     0.95682,     0.95672,     0.95662,     0.95653,     0.95666,     0.95678,     0.95691,\n",
              "            0.95703,     0.95716,     0.95729,     0.95741,     0.95754,     0.95766,     0.95779,     0.95792,     0.95804,     0.95817,      0.9585,     0.95936,      0.9601,     0.96046,     0.96083,      0.9612,     0.96156,     0.96186,     0.96207,     0.96229,     0.96251,     0.96272,     0.96294,\n",
              "            0.96316,     0.96337,     0.96389,     0.96487,     0.96547,     0.96582,     0.96617,     0.96652,     0.96687,      0.9673,     0.96778,     0.96827,     0.96876,     0.96885,     0.96891,     0.96896,     0.96901,     0.96906,     0.96911,     0.96917,     0.96922,     0.96927,     0.96932,\n",
              "            0.96937,     0.96942,     0.96948,     0.96953,     0.96958,     0.96963,     0.96968,     0.96974,     0.96979,     0.96984,     0.96989,     0.96994,     0.96999,     0.97005,      0.9701,     0.97015,      0.9702,     0.97025,     0.97031,     0.97036,     0.97041,     0.97046,     0.97051,\n",
              "            0.97056,     0.97081,     0.97124,     0.97166,     0.97208,     0.97234,     0.97221,     0.97208,     0.97195,     0.97182,     0.97169,     0.97156,     0.97143,      0.9713,     0.97117,     0.97104,      0.9709,     0.97077,     0.97064,     0.97051,     0.97079,     0.97122,     0.97164,\n",
              "            0.97206,     0.97235,     0.97252,     0.97268,     0.97285,     0.97301,     0.97317,     0.97334,      0.9735,     0.97366,     0.97383,     0.97399,     0.97411,     0.97418,     0.97425,     0.97431,     0.97438,     0.97445,     0.97452,     0.97459,     0.97466,     0.97473,      0.9748,\n",
              "            0.97487,     0.97493,       0.975,     0.97507,     0.97514,     0.97521,     0.97528,     0.97535,     0.97542,     0.97549,     0.97555,     0.97562,     0.97569,     0.97576,     0.97583,     0.97581,     0.97555,     0.97528,     0.97501,     0.97474,     0.97448,     0.97421,     0.97395,\n",
              "            0.97374,     0.97353,     0.97332,      0.9731,     0.97289,     0.97268,     0.97247,     0.97226,     0.97206,     0.97204,     0.97202,     0.97199,     0.97197,     0.97195,     0.97192,      0.9719,     0.97188,     0.97185,     0.97183,     0.97181,     0.97178,     0.97176,     0.97174,\n",
              "            0.97171,     0.97169,     0.97167,     0.97164,     0.97162,      0.9716,     0.97157,     0.97155,     0.97153,      0.9715,     0.97148,     0.97146,     0.97143,     0.97141,     0.97139,     0.97136,     0.97134,     0.97132,     0.97129,     0.97127,     0.97125,     0.97122,      0.9712,\n",
              "            0.97118,     0.97115,     0.97113,     0.97111,     0.97108,     0.97106,     0.97104,     0.97101,     0.97099,     0.97097,     0.97094,     0.97092,      0.9709,     0.97087,     0.97085,     0.97083,      0.9708,     0.97078,     0.97076,     0.97073,     0.97071,     0.97069,     0.97066,\n",
              "            0.97064,     0.97062,     0.97059,     0.97057,     0.97055,     0.97052,      0.9705,     0.97048,     0.97045,     0.97043,     0.97041,     0.97038,     0.97036,     0.97034,     0.97031,     0.97029,     0.97026,     0.97024,     0.97022,     0.97019,     0.97017,     0.97014,     0.97006,\n",
              "            0.96997,     0.96989,      0.9698,     0.96971,     0.96963,     0.96954,     0.96945,     0.96937,     0.96928,      0.9692,     0.96911,     0.96902,     0.96894,     0.96885,     0.96876,     0.96868,     0.96859,     0.96851,     0.96842,     0.96833,     0.96825,     0.96826,     0.96831,\n",
              "            0.96836,     0.96841,     0.96846,     0.96851,     0.96856,     0.96861,     0.96866,     0.96871,     0.96876,     0.96881,     0.96886,      0.9689,     0.96895,       0.969,     0.96905,      0.9691,     0.96915,      0.9692,     0.96925,      0.9693,     0.96935,      0.9694,     0.96945,\n",
              "             0.9695,     0.96955,      0.9696,     0.96965,      0.9697,     0.96974,     0.96979,     0.96984,     0.96989,     0.96994,     0.96999,     0.97003,     0.96999,     0.96994,      0.9699,     0.96985,      0.9698,     0.96976,     0.96971,     0.96966,     0.96962,     0.96957,     0.96953,\n",
              "            0.96948,     0.96943,     0.96939,     0.96934,     0.96929,     0.96925,      0.9692,     0.96915,     0.96911,     0.96906,     0.96902,     0.96897,     0.96892,     0.96888,     0.96883,     0.96878,     0.96874,     0.96869,     0.96865,      0.9686,     0.96855,     0.96851,     0.96846,\n",
              "            0.96841,     0.96837,     0.96832,     0.96827,     0.96823,     0.96818,     0.96813,     0.96812,     0.96818,     0.96823,     0.96828,     0.96833,     0.96839,     0.96844,     0.96849,     0.96854,     0.96859,     0.96865,      0.9687,     0.96875,      0.9688,     0.96886,     0.96891,\n",
              "            0.96896,     0.96901,     0.96906,     0.96912,     0.96917,     0.96922,     0.96927,     0.96933,     0.96938,     0.96943,     0.96948,     0.96953,     0.96959,     0.96964,     0.96969,     0.96974,     0.96979,     0.96985,      0.9699,     0.96795,     0.96728,      0.9666,     0.96602,\n",
              "            0.96594,     0.96585,     0.96576,     0.96568,     0.96559,      0.9655,     0.96542,     0.96533,     0.96524,     0.96516,     0.96507,     0.96498,      0.9649,     0.96481,     0.96472,     0.96464,     0.96455,     0.96446,     0.96438,     0.96429,      0.9642,     0.96412,       0.964,\n",
              "            0.96386,     0.96372,     0.96358,     0.96344,      0.9633,     0.96317,     0.96303,     0.96289,     0.96275,     0.96261,     0.96247,     0.96233,     0.96219,     0.96281,     0.96376,     0.96288,     0.96199,     0.96189,     0.96181,     0.96172,     0.96163,     0.96154,     0.96146,\n",
              "            0.96137,     0.96128,      0.9612,     0.96111,     0.96102,     0.96094,     0.96085,     0.96076,     0.96067,     0.96059,      0.9605,     0.96041,     0.96033,     0.96024,     0.96015,     0.96007,     0.95998,     0.95991,     0.95984,     0.95978,     0.95971,     0.95964,     0.95957,\n",
              "             0.9595,     0.95943,     0.95936,     0.95929,     0.95922,     0.95915,     0.95908,     0.95901,     0.95894,     0.95888,     0.95881,     0.95874,     0.95867,      0.9586,     0.95853,     0.95846,     0.95839,     0.95832,     0.95825,     0.95818,     0.95811,     0.95804,     0.95811,\n",
              "            0.95828,     0.95845,     0.95861,     0.95878,     0.95894,     0.95911,     0.95927,     0.95944,      0.9596,     0.95977,     0.95962,     0.95918,     0.95874,     0.95831,     0.95787,     0.95775,     0.95764,     0.95753,     0.95743,     0.95732,     0.95721,      0.9571,     0.95699,\n",
              "            0.95688,     0.95678,     0.95667,     0.95656,     0.95645,     0.95634,     0.95623,     0.95612,     0.95602,     0.95591,     0.95569,     0.95536,     0.95503,      0.9547,     0.95437,     0.95404,      0.9513,     0.94979,     0.94952,     0.94925,     0.94898,     0.94872,     0.94845,\n",
              "            0.94818,     0.94791,      0.9476,     0.94726,     0.94691,     0.94657,     0.94622,     0.94588,     0.94465,     0.94341,     0.94282,     0.94224,     0.94165,     0.94136,     0.94108,      0.9408,     0.94052,     0.94023,     0.93995,     0.93967,     0.93712,      0.9362,     0.93532,\n",
              "            0.93468,     0.93404,      0.9334,     0.93094,      0.9301,     0.92926,      0.9282,      0.9271,     0.92607,     0.92504,     0.92378,     0.92249,     0.92126,      0.9203,     0.91961,     0.91892,     0.91835,     0.91798,     0.91761,     0.91724,     0.91687,      0.9165,     0.91437,\n",
              "            0.91294,     0.90853,     0.90561,     0.90355,     0.90042,     0.89873,     0.89806,     0.89738,      0.8967,     0.89335,     0.88921,     0.88633,     0.88476,     0.88402,     0.88327,     0.88228,     0.88111,     0.87705,     0.87349,       0.873,     0.87252,     0.87203,     0.87154,\n",
              "            0.87057,     0.86932,       0.865,     0.85995,     0.85675,     0.85436,     0.85343,     0.85251,     0.84977,     0.84694,     0.83968,     0.83677,     0.83562,     0.83254,     0.83093,     0.82606,     0.82175,     0.81644,     0.81389,     0.81247,     0.80909,     0.80453,     0.79344,\n",
              "            0.78738,     0.78559,     0.78483,     0.78406,     0.78329,     0.77886,     0.76929,     0.76654,     0.76071,     0.75367,      0.7491,     0.74596,     0.73926,     0.73674,     0.73524,     0.73138,     0.72948,     0.72286,     0.71881,     0.71185,     0.69577,     0.68797,     0.68085,\n",
              "            0.67819,     0.67645,     0.67314,     0.67024,     0.66602,     0.65749,     0.64983,     0.64614,     0.64231,     0.62902,     0.62555,     0.61868,     0.61612,     0.61246,     0.60375,     0.60124,     0.59033,     0.58565,     0.57177,     0.56548,     0.55195,     0.55033,     0.54721,\n",
              "            0.54437,     0.54278,     0.53868,     0.52746,     0.52008,     0.51258,     0.50423,     0.49881,     0.49412,     0.49115,     0.47988,     0.46948,     0.46356,     0.45918,      0.4475,      0.4289,     0.41474,     0.40158,     0.39438,     0.38033,     0.37585,     0.36431,     0.36013,\n",
              "             0.3575,     0.34846,     0.33122,     0.32582,     0.32312,     0.31651,     0.30547,     0.28551,     0.26617,      0.2523,     0.23281,     0.22668,     0.22364,     0.22125,     0.21943,      0.2176,     0.21382,     0.20179,     0.18717,     0.17835,     0.17589,     0.17183,     0.16012,\n",
              "            0.14937,     0.14504,     0.13105,     0.12498,     0.11983,     0.10565,     0.10256,     0.10034,    0.098108,    0.087066,    0.074941,    0.048177,    0.040848,    0.037233,    0.018553,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.16667,     0.16696,     0.29367,     0.36033,     0.40917,     0.44868,     0.47428,     0.49896,     0.52772,     0.54504,     0.56862,     0.59035,     0.60723,     0.61629,     0.62513,     0.64365,     0.64929,     0.65902,      0.6736,     0.67655,     0.67775,     0.67944,     0.68487,\n",
              "            0.68848,     0.69564,     0.70387,     0.70719,     0.71117,     0.72081,     0.73383,     0.73913,     0.74215,     0.74693,     0.75197,     0.75528,     0.75838,      0.7605,     0.76551,     0.76685,       0.776,      0.7776,     0.78353,     0.78639,     0.79185,     0.79431,     0.79517,\n",
              "            0.79604,      0.7969,     0.79775,      0.7986,     0.80014,     0.80414,      0.8086,      0.8109,     0.81224,      0.8183,     0.81921,     0.82012,     0.82081,     0.82116,     0.82151,     0.82187,     0.82222,     0.82257,     0.82292,     0.82436,     0.82895,     0.83447,     0.83741,\n",
              "            0.83944,     0.84081,       0.843,     0.84606,     0.85037,     0.85188,      0.8532,     0.85491,     0.85994,     0.86057,     0.86121,     0.86184,     0.86248,     0.86346,     0.86454,     0.86583,     0.86785,     0.87084,     0.87073,     0.87078,     0.87154,     0.87231,     0.87307,\n",
              "            0.87382,     0.87455,     0.87528,     0.87601,     0.87708,     0.87828,     0.88042,     0.88471,     0.88999,     0.89194,     0.89348,     0.89427,     0.89507,     0.89586,     0.89976,     0.90104,     0.90233,     0.90497,     0.90582,     0.90631,      0.9068,      0.9073,     0.90779,\n",
              "            0.90828,     0.90902,     0.90992,     0.91082,      0.9147,     0.91775,     0.91789,     0.91798,     0.91807,     0.91816,     0.91825,     0.91833,     0.91842,     0.91851,      0.9186,     0.91868,     0.91877,     0.91886,     0.91895,     0.91904,     0.91912,     0.91921,      0.9193,\n",
              "            0.91939,     0.91948,     0.91956,     0.91965,     0.91974,     0.91983,     0.91991,        0.92,     0.92009,     0.92018,     0.92027,     0.92035,     0.92044,     0.92053,     0.92062,     0.92071,     0.92079,     0.92088,     0.92103,     0.92192,     0.92282,     0.92372,     0.92413,\n",
              "             0.9241,     0.92408,     0.92406,     0.92404,     0.92401,     0.92399,     0.92397,     0.92395,     0.92393,      0.9239,     0.92388,     0.92582,     0.92796,     0.92964,     0.93356,     0.93355,     0.93353,     0.93352,     0.93351,      0.9335,     0.93348,     0.93347,     0.93346,\n",
              "            0.93345,     0.93343,     0.93342,     0.93341,      0.9334,     0.93338,     0.93337,     0.93336,     0.93334,     0.93337,     0.93364,     0.93391,     0.93419,     0.93446,     0.93474,     0.93501,     0.93529,     0.93556,     0.93583,     0.93611,     0.93638,     0.93664,     0.93679,\n",
              "            0.93694,     0.93709,     0.93723,     0.93738,     0.93753,     0.93768,     0.93783,     0.93797,     0.93812,     0.93827,     0.93842,     0.93857,     0.93872,     0.93886,     0.93901,     0.93916,     0.93931,     0.93946,     0.93961,     0.93975,      0.9399,     0.94027,     0.94069,\n",
              "            0.94111,     0.94152,     0.94194,     0.94236,     0.94278,     0.94319,     0.94325,     0.94324,     0.94323,     0.94322,     0.94321,      0.9432,     0.94319,     0.94318,     0.94317,     0.94315,     0.94314,     0.94313,     0.94312,     0.94311,      0.9431,     0.94309,     0.94308,\n",
              "            0.94307,     0.94306,     0.94304,     0.94303,     0.94302,     0.94301,       0.943,     0.94299,     0.94298,     0.94297,     0.94296,     0.94295,     0.94293,     0.94292,     0.94291,      0.9429,     0.94289,     0.94288,     0.94287,     0.94287,     0.94312,     0.94336,     0.94361,\n",
              "            0.94385,      0.9441,     0.94434,     0.94459,     0.94483,     0.94508,     0.94532,     0.94557,     0.94581,     0.94606,     0.94671,     0.94839,     0.94983,     0.95055,     0.95126,     0.95198,      0.9527,     0.95328,      0.9537,     0.95413,     0.95456,     0.95498,     0.95541,\n",
              "            0.95584,     0.95626,     0.95729,     0.95922,     0.96041,     0.96111,      0.9618,     0.96249,     0.96318,     0.96402,     0.96499,     0.96596,     0.96693,     0.96713,     0.96723,     0.96733,     0.96744,     0.96754,     0.96764,     0.96775,     0.96785,     0.96795,     0.96806,\n",
              "            0.96816,     0.96826,     0.96837,     0.96847,     0.96857,     0.96868,     0.96878,     0.96888,     0.96899,     0.96909,     0.96919,      0.9693,      0.9694,     0.96951,     0.96961,     0.96971,     0.96982,     0.96992,     0.97002,     0.97013,     0.97023,     0.97033,     0.97044,\n",
              "            0.97054,     0.97104,     0.97189,     0.97273,     0.97358,     0.97417,     0.97416,     0.97415,     0.97415,     0.97414,     0.97413,     0.97413,     0.97412,     0.97412,     0.97411,      0.9741,      0.9741,     0.97409,     0.97408,     0.97408,     0.97471,     0.97556,     0.97641,\n",
              "            0.97727,     0.97786,     0.97819,     0.97852,     0.97885,     0.97918,     0.97952,     0.97985,     0.98018,     0.98051,     0.98084,     0.98117,     0.98141,     0.98155,     0.98169,     0.98183,     0.98197,     0.98211,     0.98225,     0.98239,     0.98253,     0.98267,     0.98281,\n",
              "            0.98295,     0.98309,     0.98323,     0.98337,     0.98351,     0.98365,     0.98379,     0.98393,     0.98407,     0.98421,     0.98435,     0.98449,     0.98463,     0.98477,     0.98491,     0.98502,     0.98501,       0.985,     0.98499,     0.98499,     0.98498,     0.98497,     0.98496,\n",
              "            0.98496,     0.98495,     0.98494,     0.98494,     0.98493,     0.98492,     0.98492,     0.98491,     0.98491,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,      0.9849,\n",
              "             0.9849,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98489,     0.98488,     0.98488,     0.98488,     0.98488,     0.98488,     0.98488,     0.98488,     0.98488,\n",
              "            0.98488,     0.98488,     0.98488,     0.98488,     0.98488,     0.98488,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98487,     0.98486,     0.98486,\n",
              "            0.98486,     0.98486,     0.98486,     0.98486,     0.98486,     0.98486,     0.98486,     0.98486,     0.98486,     0.98486,     0.98486,     0.98486,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,     0.98485,\n",
              "            0.98484,     0.98484,     0.98484,     0.98484,     0.98483,     0.98483,     0.98483,     0.98483,     0.98482,     0.98482,     0.98482,     0.98481,     0.98481,     0.98481,     0.98481,      0.9848,      0.9848,      0.9848,      0.9848,     0.98479,     0.98479,     0.98487,     0.98497,\n",
              "            0.98507,     0.98517,     0.98528,     0.98538,     0.98548,     0.98558,     0.98569,     0.98579,     0.98589,     0.98599,      0.9861,      0.9862,      0.9863,      0.9864,     0.98651,     0.98661,     0.98671,     0.98681,     0.98692,     0.98702,     0.98712,     0.98722,     0.98733,\n",
              "            0.98743,     0.98753,     0.98763,     0.98774,     0.98784,     0.98794,     0.98804,     0.98815,     0.98825,     0.98835,     0.98845,     0.98855,     0.98855,     0.98855,     0.98855,     0.98855,     0.98854,     0.98854,     0.98854,     0.98854,     0.98854,     0.98854,     0.98854,\n",
              "            0.98854,     0.98854,     0.98853,     0.98853,     0.98853,     0.98853,     0.98853,     0.98853,     0.98853,     0.98853,     0.98853,     0.98853,     0.98852,     0.98852,     0.98852,     0.98852,     0.98852,     0.98852,     0.98852,     0.98852,     0.98852,     0.98851,     0.98851,\n",
              "            0.98851,     0.98851,     0.98851,     0.98851,     0.98851,     0.98851,     0.98851,     0.98854,     0.98865,     0.98876,     0.98887,     0.98898,     0.98909,      0.9892,     0.98931,     0.98942,     0.98953,     0.98964,     0.98974,     0.98985,     0.98996,     0.99007,     0.99018,\n",
              "            0.99029,      0.9904,     0.99051,     0.99062,     0.99073,     0.99084,     0.99094,     0.99105,     0.99116,     0.99127,     0.99138,     0.99149,      0.9916,     0.99171,     0.99182,     0.99193,     0.99203,     0.99214,     0.99225,     0.99228,     0.99227,     0.99226,     0.99225,\n",
              "            0.99225,     0.99225,     0.99224,     0.99224,     0.99224,     0.99224,     0.99224,     0.99224,     0.99224,     0.99223,     0.99223,     0.99223,     0.99223,     0.99223,     0.99223,     0.99223,     0.99223,     0.99222,     0.99222,     0.99222,     0.99222,     0.99222,     0.99222,\n",
              "            0.99221,     0.99221,     0.99221,     0.99221,     0.99221,      0.9922,      0.9922,      0.9922,      0.9922,      0.9922,     0.99219,     0.99219,     0.99219,     0.99365,     0.99608,     0.99607,     0.99606,     0.99606,     0.99606,     0.99606,     0.99606,     0.99606,     0.99606,\n",
              "            0.99606,     0.99606,     0.99606,     0.99606,     0.99606,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99605,     0.99604,     0.99604,\n",
              "            0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99604,     0.99603,     0.99603,     0.99603,     0.99603,     0.99603,     0.99603,     0.99625,\n",
              "             0.9966,     0.99696,     0.99732,     0.99768,     0.99804,      0.9984,     0.99876,     0.99911,     0.99947,     0.99983,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.99632,     0.99632,     0.99632,     0.99632,     0.99632,     0.99632,     0.99632,     0.99632,     0.99632,     0.99632,     0.99632,     0.99632,     0.99632,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,\n",
              "            0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,\n",
              "            0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,\n",
              "            0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99265,     0.99052,     0.98897,     0.98897,     0.98897,     0.98897,\n",
              "            0.98897,     0.98897,     0.98897,     0.98897,     0.98897,     0.98897,     0.98897,     0.98743,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,\n",
              "            0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,\n",
              "            0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98529,     0.98513,\n",
              "            0.98482,     0.98451,     0.98419,     0.98388,     0.98357,     0.98326,     0.98295,     0.98264,     0.98232,     0.98201,      0.9817,     0.98162,     0.98162,     0.98162,     0.98151,     0.98131,     0.98111,     0.98091,     0.98071,     0.98051,     0.98031,     0.98011,     0.97991,\n",
              "            0.97971,     0.97951,     0.97931,     0.97911,     0.97892,     0.97872,     0.97852,     0.97832,     0.97812,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,\n",
              "            0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,\n",
              "            0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97794,     0.97777,     0.97758,     0.97738,     0.97718,     0.97698,     0.97678,     0.97658,     0.97638,     0.97618,     0.97598,     0.97578,     0.97558,     0.97538,     0.97518,     0.97498,     0.97478,     0.97458,\n",
              "            0.97438,     0.97418,     0.97398,     0.97378,     0.97358,     0.97338,     0.97318,     0.97298,     0.97278,     0.97258,     0.97238,     0.97218,     0.97198,     0.97178,     0.97158,     0.97138,     0.97118,     0.97098,     0.97078,     0.97059,     0.97059,     0.97059,     0.97059,\n",
              "            0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,\n",
              "            0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,\n",
              "            0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97059,\n",
              "            0.97059,     0.97059,     0.97059,     0.97059,     0.97059,     0.97051,     0.97026,     0.97001,     0.96975,      0.9695,     0.96925,       0.969,     0.96874,     0.96849,     0.96824,     0.96799,     0.96773,     0.96748,     0.96723,     0.96698,     0.96691,     0.96691,     0.96691,\n",
              "            0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,\n",
              "            0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96691,     0.96678,     0.96626,     0.96575,     0.96523,     0.96471,      0.9642,     0.96368,     0.96318,\n",
              "            0.96277,     0.96237,     0.96196,     0.96155,     0.96114,     0.96074,     0.96033,     0.95992,     0.95955,     0.95951,     0.95946,     0.95942,     0.95937,     0.95933,     0.95929,     0.95924,      0.9592,     0.95915,     0.95911,     0.95906,     0.95902,     0.95897,     0.95893,\n",
              "            0.95888,     0.95884,     0.95879,     0.95875,      0.9587,     0.95866,     0.95861,     0.95857,     0.95852,     0.95848,     0.95843,     0.95839,     0.95834,      0.9583,     0.95825,     0.95821,     0.95816,     0.95812,     0.95808,     0.95803,     0.95799,     0.95794,      0.9579,\n",
              "            0.95785,     0.95781,     0.95776,     0.95772,     0.95767,     0.95763,     0.95758,     0.95754,     0.95749,     0.95745,      0.9574,     0.95736,     0.95731,     0.95727,     0.95722,     0.95718,     0.95713,     0.95709,     0.95704,       0.957,     0.95696,     0.95691,     0.95687,\n",
              "            0.95682,     0.95678,     0.95673,     0.95669,     0.95664,      0.9566,     0.95655,     0.95651,     0.95646,     0.95642,     0.95637,     0.95633,     0.95628,     0.95624,     0.95619,     0.95615,      0.9561,     0.95606,     0.95601,     0.95597,     0.95592,     0.95587,     0.95571,\n",
              "            0.95554,     0.95538,     0.95521,     0.95505,     0.95488,     0.95472,     0.95455,     0.95439,     0.95423,     0.95406,      0.9539,     0.95373,     0.95357,      0.9534,     0.95324,     0.95307,     0.95291,     0.95274,     0.95258,     0.95241,     0.95225,     0.95221,     0.95221,\n",
              "            0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,\n",
              "            0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,     0.95221,      0.9522,     0.95211,     0.95202,     0.95194,     0.95185,     0.95176,     0.95167,     0.95158,     0.95149,     0.95141,     0.95132,     0.95123,\n",
              "            0.95114,     0.95105,     0.95097,     0.95088,     0.95079,      0.9507,     0.95061,     0.95053,     0.95044,     0.95035,     0.95026,     0.95017,     0.95008,        0.95,     0.94991,     0.94982,     0.94973,     0.94964,     0.94956,     0.94947,     0.94938,     0.94929,      0.9492,\n",
              "            0.94911,     0.94903,     0.94894,     0.94885,     0.94876,     0.94867,     0.94859,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,\n",
              "            0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94853,     0.94479,     0.94351,     0.94223,     0.94115,\n",
              "            0.94099,     0.94082,     0.94066,      0.9405,     0.94033,     0.94017,     0.94001,     0.93984,     0.93968,     0.93952,     0.93936,     0.93919,     0.93903,     0.93887,      0.9387,     0.93854,     0.93838,     0.93821,     0.93805,     0.93789,     0.93773,     0.93756,     0.93734,\n",
              "            0.93708,     0.93682,     0.93656,      0.9363,     0.93604,     0.93578,     0.93552,     0.93526,       0.935,     0.93474,     0.93448,     0.93422,     0.93396,     0.93382,     0.93347,     0.93182,     0.93018,     0.92999,     0.92983,     0.92966,      0.9295,     0.92934,     0.92918,\n",
              "            0.92902,     0.92886,     0.92869,     0.92853,     0.92837,     0.92821,     0.92805,     0.92789,     0.92772,     0.92756,      0.9274,     0.92724,     0.92708,     0.92692,     0.92675,     0.92659,     0.92644,     0.92631,     0.92618,     0.92605,     0.92593,      0.9258,     0.92567,\n",
              "            0.92554,     0.92541,     0.92528,     0.92516,     0.92503,      0.9249,     0.92477,     0.92464,     0.92451,     0.92439,     0.92426,     0.92413,       0.924,     0.92387,     0.92374,     0.92362,     0.92349,     0.92336,     0.92323,      0.9231,     0.92297,     0.92285,     0.92279,\n",
              "            0.92279,     0.92279,     0.92279,     0.92279,     0.92279,     0.92279,     0.92279,     0.92279,     0.92279,     0.92279,     0.92237,     0.92156,     0.92076,     0.91995,     0.91915,     0.91893,     0.91873,     0.91853,     0.91833,     0.91813,     0.91793,     0.91773,     0.91753,\n",
              "            0.91733,     0.91713,     0.91693,     0.91673,     0.91654,     0.91634,     0.91614,     0.91594,     0.91574,     0.91554,     0.91514,     0.91453,     0.91393,     0.91333,     0.91272,     0.91212,     0.90713,     0.90438,     0.90389,     0.90341,     0.90292,     0.90244,     0.90195,\n",
              "            0.90146,     0.90098,     0.90043,      0.8998,     0.89918,     0.89856,     0.89794,     0.89732,      0.8951,     0.89287,     0.89183,     0.89078,     0.88974,     0.88922,     0.88872,     0.88821,     0.88771,     0.88721,      0.8867,      0.8862,     0.88167,     0.88005,      0.8785,\n",
              "            0.87737,     0.87624,     0.87511,     0.87081,     0.86934,     0.86787,     0.86602,      0.8641,     0.86232,     0.86054,     0.85835,     0.85613,     0.85402,     0.85236,     0.85118,        0.85,     0.84903,      0.8484,     0.84777,     0.84714,      0.8465,     0.84587,     0.84225,\n",
              "            0.83983,      0.8324,      0.8275,     0.82407,     0.81888,     0.81609,     0.81498,     0.81386,     0.81275,     0.80726,     0.80053,     0.79586,     0.79334,     0.79214,     0.79095,     0.78936,     0.78749,     0.78102,      0.7754,     0.77463,     0.77386,      0.7731,     0.77233,\n",
              "             0.7708,     0.76885,     0.76212,     0.75431,     0.74941,     0.74574,     0.74434,     0.74294,     0.73878,     0.73451,     0.72366,     0.71935,     0.71766,     0.71312,     0.71075,     0.70367,     0.69744,     0.68981,     0.68619,     0.68417,     0.67939,     0.67299,     0.65761,\n",
              "            0.64933,     0.64689,     0.64586,     0.64482,     0.64378,     0.63782,     0.62508,     0.62145,     0.61382,     0.60471,     0.59885,     0.59485,     0.58637,      0.5832,     0.58133,     0.57652,     0.57416,       0.566,     0.56105,     0.55262,     0.53347,     0.52435,     0.51612,\n",
              "            0.51307,     0.51109,     0.50732,     0.50404,     0.49928,     0.48975,      0.4813,     0.47726,     0.47309,     0.45881,     0.45513,     0.44789,     0.44521,      0.4414,      0.4324,     0.42984,     0.41877,     0.41407,     0.40034,      0.3942,     0.38117,     0.37963,     0.37666,\n",
              "            0.37398,     0.37248,     0.36862,      0.3582,     0.35143,     0.34461,     0.33711,     0.33228,     0.32813,     0.32551,     0.31569,     0.30675,     0.30171,     0.29801,     0.28825,       0.273,     0.26162,     0.25124,     0.24563,     0.23482,     0.23141,     0.22273,     0.21961,\n",
              "            0.21766,     0.21099,     0.19848,     0.19462,     0.19269,     0.18801,     0.18027,     0.16653,     0.15352,     0.14436,     0.13174,     0.12783,      0.1259,     0.12439,     0.12323,     0.12208,     0.11971,     0.11222,     0.10325,    0.097905,    0.096426,    0.093992,    0.087026,\n",
              "           0.080714,    0.078191,    0.070121,    0.066653,    0.063732,    0.055773,    0.054053,    0.052819,    0.051585,    0.045514,    0.038929,    0.024683,     0.02085,     0.01897,   0.0093632,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.8855127325046135)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.87364])\n",
              "names: {0: 'crosswalk'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': np.float64(0.9839334937540454), 'metrics/recall(B)': np.float64(0.9669117647058824), 'metrics/mAP50(B)': np.float64(0.9924065838579195), 'metrics/mAP50-95(B)': np.float64(0.8736356379098016), 'fitness': np.float64(0.8855127325046135)}\n",
              "save_dir: PosixPath('crosswalk_yolo/yolov8n_crosswalk2')\n",
              "speed: {'preprocess': 2.62595291424077, 'inference': 264.23786324286044, 'loss': 6.0671404103881544e-05, 'postprocess': 0.6359571952392191}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Step 1: Install YOLOv8\n",
        "!pip install ultralytics\n",
        "\n",
        "# Step 2: Unzip your dataset\n",
        "import zipfile\n",
        "zip_path = \"/content/crosswalk-detection.v1i.yolov8.zip\"\n",
        "extract_path = \"/content/crosswalk-detection\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Step 3: Train the YOLOv8 model with enhanced settings\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")  # Use 'yolov8s.pt' for better accuracy but slower\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/crosswalk-detection/data.yaml\",  # dataset config\n",
        "    epochs=50,  # max epochs\n",
        "    imgsz=640,  # image size\n",
        "    batch=16,   # batch size\n",
        "    patience=10,  # ⬅️ NEW: Stop early if val_loss doesn't improve in 10 epochs\n",
        "    project=\"crosswalk_yolo\",\n",
        "    name=\"yolov8n_crosswalk\",\n",
        "    verbose=True  # show detailed logging\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best weights from training\n",
        "model = YOLO(\"/content/crosswalk_yolo/yolov8n_crosswalk/weights/best.pt\")\n",
        "\n",
        "# Export to TFLite\n",
        "model.export(format=\"tflite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ptq1eFZXSV8G",
        "outputId": "6632c1b8-8a99-4bf9-e05b-bc8cbcfb71f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.131 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/crosswalk_yolo/yolov8n_crosswalk/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (17.6 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx>=1.12.0', 'onnx2tf>=1.26.3', 'onnxslim>=0.1.46', 'onnxruntime'] not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting sng4onnx>=1.0.1\n",
            "  Downloading sng4onnx-1.0.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting onnx_graphsurgeon>=0.3.26\n",
            "  Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting ai-edge-litert>=1.2.0\n",
            "  Downloading ai_edge_litert-1.2.0-cp311-cp311-manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnx2tf>=1.26.3\n",
            "  Downloading onnx2tf-1.27.2-py3-none-any.whl.metadata (147 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.7/147.7 kB 10.7 MB/s eta 0:00:00\n",
            "Collecting onnxslim>=0.1.46\n",
            "  Downloading onnxslim-0.1.52-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnx_graphsurgeon>=0.3.26) (2.0.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert>=1.2.0) (25.2.10)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxslim>=0.1.46) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxslim>=0.1.46) (24.2)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxslim>=0.1.46) (1.3.0)\n",
            "Downloading sng4onnx-1.0.4-py3-none-any.whl (5.9 kB)\n",
            "Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.9/57.9 kB 219.9 MB/s eta 0:00:00\n",
            "Downloading ai_edge_litert-1.2.0-cp311-cp311-manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 115.2 MB/s eta 0:00:00\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 210.0 MB/s eta 0:00:00\n",
            "Downloading onnx2tf-1.27.2-py3-none-any.whl (446 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 446.6/446.6 kB 150.3 MB/s eta 0:00:00\n",
            "Downloading onnxslim-0.1.52-py3-none-any.whl (145 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 145.6/145.6 kB 124.9 MB/s eta 0:00:00\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 265.4 MB/s eta 0:00:00\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 163.6 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 206.4 MB/s eta 0:00:00\n",
            "Installing collected packages: sng4onnx, onnx2tf, onnx, humanfriendly, ai-edge-litert, onnxslim, onnx_graphsurgeon, coloredlogs, onnxruntime\n",
            "Successfully installed ai-edge-litert-1.2.0 coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnx2tf-1.27.2 onnx_graphsurgeon-0.5.8 onnxruntime-1.22.0 onnxslim-0.1.52 sng4onnx-1.0.4\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 16.4s, installed 7 packages: ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx>=1.12.0', 'onnx2tf>=1.26.3', 'onnxslim>=0.1.46', 'onnxruntime']\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.11M/1.11M [00:00<00:00, 29.1MB/s]\n",
            "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|██████████| 1/1 [00:00<00:00, 42.92file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.52...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.2s, saved as '/content/crosswalk_yolo/yolov8n_crosswalk/weights/best.onnx' (11.8 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.27.2...\n",
            "Saved artifact at '/content/crosswalk_yolo/yolov8n_crosswalk/weights/best_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 5, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134562487094544: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134562487094352: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  134562487094928: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  134562487098768: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134562487098384: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  134562487094736: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134562487095312: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  134562487099344: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134562487099536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562487099728: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562487101840: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  134562487102224: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  134562487100880: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  134562487102608: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  134562487099920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562487096272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562487101072: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
            "  134562487100496: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134562487102416: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134562487102800: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  134562487102992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562487103184: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562487103568: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562487103952: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562487103760: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562487104528: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  134562487105872: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134562487105104: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  134562487106256: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134562487105296: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  134562487106448: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134562487104720: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  134562487106640: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134562487104144: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562487103376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562487107216: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  134562487107024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562487106832: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134562487106064: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  134562487107408: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562450571344: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  134562450571728: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562450572112: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450571920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450572688: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562450574032: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450574416: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562450573264: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450572880: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562450574608: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450573456: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562450574800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450572304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450571536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450575376: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  134562450575184: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562450575568: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134562450574224: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  134562450574992: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134562450575760: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  134562450576144: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134562450576528: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450576336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450577104: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134562450578448: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562450577680: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134562450578832: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562450576720: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450575952: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450579024: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  134562450577872: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134562450577296: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  134562450579216: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562450579408: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  134562450579600: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134562450579984: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  134562450579792: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562450580368: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450580176: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450580944: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562450582288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450581520: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562450582672: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450580560: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450578640: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450581712: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  134562450582480: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562450582864: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
            "  134562450583056: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450583440: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450583248: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450584016: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  134562450585360: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134562450584592: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  134562450585744: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  134562450583632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450581136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450584784: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  134562450585552: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450586128: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134562450585936: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562450584208: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562495494480: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  134562495494864: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562495494096: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562495495056: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562450587472: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562450587088: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562495491600: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562495491024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562495493328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562495491984: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562495491408: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  134562495489296: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562486780176: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  134562495490640: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134562486779984: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562486781904: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  134562486782096: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134562486783056: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562486783248: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562486785744: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134562486784016: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562486785552: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  134562486786320: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  134562486783440: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562486783632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  134562486784784: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  134562486784208: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  134562486785936: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  134562486784592: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  134562486780752: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  134562486780368: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  134562450586704: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562450586320: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562486786512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486785360: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486780944: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486780560: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450586896: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562450586512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486786704: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562486786896: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562486781712: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562486781136: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562495495632: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562487096080: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562486786128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486787088: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486781520: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486781328: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562495494672: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562487093968: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486787280: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n",
            "  134562486787664: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562486782288: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n",
            "  134562486782864: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562495493904: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n",
            "  134562495493520: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  134562486787856: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486787472: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n",
            "  134562486782480: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562486782672: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n",
            "  134562495493712: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  134562495494288: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n",
            "  134562486789584: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  134562486790352: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  134562486792464: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  134562486793424: TensorSpec(shape=(1, 4, 8400), dtype=tf.float32, name=None)\n",
            "  134562486791504: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  134562486790160: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  134562486791120: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  134562486789968: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  134562486792080: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  134562486792848: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  134562486788816: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  134562486789776: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 52.3s, saved as '/content/crosswalk_yolo/yolov8n_crosswalk/weights/best_saved_model' (29.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ✅ 0.0s, saved as '/content/crosswalk_yolo/yolov8n_crosswalk/weights/best_saved_model/best_float32.tflite' (11.7 MB)\n",
            "\n",
            "Export complete (53.0s)\n",
            "Results saved to \u001b[1m/content/crosswalk_yolo/yolov8n_crosswalk/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/crosswalk_yolo/yolov8n_crosswalk/weights/best_saved_model/best_float32.tflite imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/crosswalk_yolo/yolov8n_crosswalk/weights/best_saved_model/best_float32.tflite imgsz=640 data=/content/crosswalk-detection/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/crosswalk_yolo/yolov8n_crosswalk/weights/best_saved_model/best_float32.tflite'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/crosswalk_yolo/yolov8n_crosswalk/weights/best_saved_model/best_float32.tflite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_9AdPKTKSz64",
        "outputId": "02ea56dd-a6b3-4669-a608-5c0cfd2bf879"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_977c6d0e-0646-4dba-91a0-a5075cb769f7\", \"best_float32.tflite\", 12315795)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/crosswalk_yolo/yolov8n_crosswalk/weights/best.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VKG95E9bUmle",
        "outputId": "67518909-a4a1-458e-82ce-1eacda9f746a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0bdb12f4-20fd-4594-ac85-4664bc23ece4\", \"best.pt\", 18455318)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}